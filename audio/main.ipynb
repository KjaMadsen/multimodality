{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from dataset import AudioDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import torch\n",
    "from model import LSTMnet_RnnAtten\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kjart\\OneDrive\\Dokumenter\\KU\\2. semester\\CogSci2\\research\\multimodal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "train_annotations = '.\\\\data\\\\MELD\\\\train_sent_emo.csv'\n",
    "val_annotations = 'data\\MELD\\dev_sent_emo.csv'\n",
    "\n",
    "train_audio = '.\\\\data\\\\MELD\\\\audio\\\\wav\\\\'\n",
    "val_audio = '.\\\\data\\\\MELD\\\\audio\\\\wav_dev\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = AudioDataset(train_annotations, train_audio)\n",
    "#val = AudioDataset(val_annotations, val_audio)\n",
    "\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=64, shuffle = True, drop_last=False)\n",
    "val_dataloader = DataLoader(val, batch_size=64, shuffle=True, drop_last=False)\n",
    "train_features, train_labels = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1611])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1611]), tensor(4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check: Size should be [batch_size, num_features, feature_vector_len], [batch_size]\n",
    "# Where batch size is 32, num_features (num mfccs) is 40 \n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "features = train_features[0]\n",
    "label = train_labels[0]\n",
    "\n",
    "features.shape,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1611]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    x, y = batch\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fnc(predictions, targets):\n",
    "    return nn.CrossEntropyLoss()(input=predictions,target=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step(model, loss_fnc, optimizer):\n",
    "    def train_step(X,Y):\n",
    "        # set model to train mode\n",
    "        model.train()\n",
    "        # forward pass\n",
    "        output_logits = model(X)\n",
    "        predictions = torch.argmax(output_logits,dim=1)\n",
    "        accuracy = torch.sum(Y==predictions)/float(len(Y))\n",
    "        f1 = f1_score(Y, predictions, average='weighted')\n",
    "        # compute loss\n",
    "        loss = loss_fnc(output_logits, Y)\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        # update parameters and zero gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item(), accuracy*100, f1*100\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_validate_fnc(model,loss_fnc):\n",
    "    def validate(X,Y):\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            output_logits = model(X)\n",
    "            predictions = torch.argmax(output_logits,dim=1)\n",
    "            accuracy = torch.sum(Y==predictions)/float(len(Y))\n",
    "            f1 = f1_score(Y, predictions, average='weighted')\n",
    "            loss = loss_fnc(output_logits,Y)\n",
    "        return loss.item(), accuracy*100, f1*100, predictions\n",
    "    return validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable params:  4415495\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = LSTMnet_RnnAtten(input_dim = 1611, hidden_dim=256, output_dim=7, num_layers=5).to(device)\n",
    "print('Number of trainable params: ',sum(p.numel() for p in model.parameters()) )\n",
    "OPTIMIZER = torch.optim.Adam(model.parameters(),lr=0.0001, weight_decay=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 --> loss:1.7092, acc:37.64%, f1:28.41%, val_loss:1.8161, val_acc:42.19%, val_f1:25.03%\n",
      "\n",
      "Epoch 1 --> loss:1.5649, acc:47.50%, f1:24.66%, val_loss:1.3892, val_acc:56.25%, val_f1:40.50%\n",
      "\n",
      "Epoch 2 --> loss:1.5511, acc:47.53%, f1:30.35%, val_loss:1.6300, val_acc:40.62%, val_f1:23.47%\n",
      "\n",
      "Epoch 3 --> loss:1.5476, acc:47.53%, f1:24.66%, val_loss:1.5413, val_acc:48.44%, val_f1:31.61%\n"
     ]
    }
   ],
   "source": [
    "train_step = make_train_step(model, loss_fnc, optimizer=OPTIMIZER)\n",
    "validate = make_validate_fnc(model,loss_fnc)\n",
    "\n",
    "losses=[]\n",
    "val_losses = []\n",
    "f1s = []\n",
    "val_f1s= []\n",
    "epochs = 150\n",
    "for epoch in range(epochs):\n",
    "    epoch_acc = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_f1 = 0\n",
    "    for idx, (features, labels) in enumerate(train_dataloader):\n",
    "        X, Y = features, labels\n",
    "        X_tensor = torch.tensor(X,device=device).float()\n",
    "        Y_tensor = torch.tensor(Y, dtype=torch.long,device=device)\n",
    "        loss, acc, f1 = train_step(X_tensor,Y_tensor)\n",
    "        epoch_acc += acc*len(features)/len(train)\n",
    "        epoch_loss += loss*len(features)/len(train)\n",
    "        epoch_f1 += f1*len(features)/len(train)\n",
    "    for batch in val_dataloader:\n",
    "        X_val, Y_val = batch\n",
    "        break\n",
    "    X_val_tensor = torch.tensor(X_val,device=device).float()\n",
    "    Y_val_tensor = torch.tensor(Y_val,dtype=torch.long,device=device)\n",
    "    val_loss, val_acc, val_f1, _ = validate(X_val_tensor,Y_val_tensor)\n",
    "    losses.append(epoch_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    f1s.append(epoch_f1)\n",
    "    val_f1s.append(val_f1)\n",
    "    print('')\n",
    "    print(f\"Epoch {epoch} --> loss:{epoch_loss:.4f}, acc:{epoch_acc:.2f}%, f1:{f1:.2f}%, val_loss:{val_loss:.4f}, val_acc:{val_acc:.2f}%, val_f1:{val_f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40a9768d250eb22e51b6c5a3b41fdf4e51420751aaeb4dd105d54b23da568f3d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
